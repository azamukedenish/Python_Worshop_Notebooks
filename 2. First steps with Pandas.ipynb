{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Data Analysis with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "***Note***: this notebook contains cell with ***a*** solution. Remember ther is not only one solution to a problem!  \n",
    "You will recognise these cells as they start with **# %**.  \n",
    "If you would like to see the solution, you will have to remove the **#** (which can be done by using **Ctrl** and **?**) and run the cell. If you want to run the solution code, you will have to run the cell again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Data Ananlysis Packages  \n",
    "Data Scientists use a wide variety of libraries in Python that make working with data significantly easier. Those libraries primarily consist of:\n",
    "\n",
    "| Package | Description |\n",
    "| -- | -- |\n",
    "| `NumPy` | Numerical calculations - does all the heavy lifting by passing out to C subroutines. This means you get _both_ the productivity of Python, _and_ the computational power of C. Best of both worlds! |\n",
    "| `SciPy` | Scientific computing, statistic tests, and much more! |\n",
    "| `pandas` | Your data manipulation swiss army knife. You'll likely see pandas used in any PyData demo! pandas is built on top of NumPy, so it's **fast**. |\n",
    "| `matplotlib` | An old but powerful data visualisation package, inspired by Matlab. |\n",
    "| `Seaborn` | A newer and easy-to-use but limited data visualisation package, built on top of matplotlib. |\n",
    "| `scikit-learn` | Your one-stop machine learning shop! Classification, regression, clustering, dimensional reduction and more. |\n",
    "| `nltk` and `spacy` | nltk = natural language processing toolkit; spacy is a newer package for natural language processing but very easy to use. |\n",
    "| `statsmodels` | Statistical tests, time series forecasting and more. The \"model formula\" interface will be familiar to R users. |\n",
    "| `requests` and `Beautiful Soup` | `requests` + `Beautiful Soup` = great combination for building web scrapers. |\n",
    "| `Jupyter` | Jupyter itself is a package too. See the latest version at https://pypi.org/project/jupyter/, and upgrade with e.g. `conda install jupyter==1.0.0` |\n",
    "\n",
    "Though there are countless others available.\n",
    "\n",
    "For today, we'll primarily focus ourselves around the library that is 99% of our work: `pandas`. Pandas is built on top of the speed and power of NumPy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "___\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
    }
   },
   "outputs": [
   ],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    ">Import numpy using the convention seen at the end of the first notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
    }
   },
   "outputs": [
   ],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
    }
   },
   "outputs": [
   ],
   "source": [
    "# %load ../solutions/02_01.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "___\n",
    "## Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "To see a method's documentation, you can use the help function. In jupyter notebook, you can also just put a question mark before the method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIO\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mAnyStr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'infer'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msqueeze\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmangle_dupe_cols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mconverters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtrue_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfalse_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mskipinitialspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mskiprows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mskipfooter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mna_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mkeep_default_na\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mna_filter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mskip_blank_lines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0minfer_datetime_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mkeep_date_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdate_parser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdayfirst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcache_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0miterator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'infer'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mthousands\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdecimal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlineterminator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mquotechar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\"'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mquoting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdoublequote\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mescapechar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcomment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdialect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0merror_bad_lines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mwarn_bad_lines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdelim_whitespace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlow_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfloat_precision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Read a comma-separated values (csv) file into DataFrame.\n",
       "\n",
       "Also supports optionally iterating or breaking of the file\n",
       "into chunks.\n",
       "\n",
       "Additional help can be found in the online docs for\n",
       "`IO Tools <https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html>`_.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "filepath_or_buffer : str, path object or file-like object\n",
       "    Any valid string path is acceptable. The string could be a URL. Valid\n",
       "    URL schemes include http, ftp, s3, gs, and file. For file URLs, a host is\n",
       "    expected. A local file could be: file://localhost/path/to/table.csv.\n",
       "\n",
       "    If you want to pass in a path object, pandas accepts any ``os.PathLike``.\n",
       "\n",
       "    By file-like object, we refer to objects with a ``read()`` method, such as\n",
       "    a file handler (e.g. via builtin ``open`` function) or ``StringIO``.\n",
       "sep : str, default ','\n",
       "    Delimiter to use. If sep is None, the C engine cannot automatically detect\n",
       "    the separator, but the Python parsing engine can, meaning the latter will\n",
       "    be used and automatically detect the separator by Python's builtin sniffer\n",
       "    tool, ``csv.Sniffer``. In addition, separators longer than 1 character and\n",
       "    different from ``'\\s+'`` will be interpreted as regular expressions and\n",
       "    will also force the use of the Python parsing engine. Note that regex\n",
       "    delimiters are prone to ignoring quoted data. Regex example: ``'\\r\\t'``.\n",
       "delimiter : str, default ``None``\n",
       "    Alias for sep.\n",
       "header : int, list of int, default 'infer'\n",
       "    Row number(s) to use as the column names, and the start of the\n",
       "    data.  Default behavior is to infer the column names: if no names\n",
       "    are passed the behavior is identical to ``header=0`` and column\n",
       "    names are inferred from the first line of the file, if column\n",
       "    names are passed explicitly then the behavior is identical to\n",
       "    ``header=None``. Explicitly pass ``header=0`` to be able to\n",
       "    replace existing names. The header can be a list of integers that\n",
       "    specify row locations for a multi-index on the columns\n",
       "    e.g. [0,1,3]. Intervening rows that are not specified will be\n",
       "    skipped (e.g. 2 in this example is skipped). Note that this\n",
       "    parameter ignores commented lines and empty lines if\n",
       "    ``skip_blank_lines=True``, so ``header=0`` denotes the first line of\n",
       "    data rather than the first line of the file.\n",
       "names : array-like, optional\n",
       "    List of column names to use. If the file contains a header row,\n",
       "    then you should explicitly pass ``header=0`` to override the column names.\n",
       "    Duplicates in this list are not allowed.\n",
       "index_col : int, str, sequence of int / str, or False, default ``None``\n",
       "  Column(s) to use as the row labels of the ``DataFrame``, either given as\n",
       "  string name or column index. If a sequence of int / str is given, a\n",
       "  MultiIndex is used.\n",
       "\n",
       "  Note: ``index_col=False`` can be used to force pandas to *not* use the first\n",
       "  column as the index, e.g. when you have a malformed file with delimiters at\n",
       "  the end of each line.\n",
       "usecols : list-like or callable, optional\n",
       "    Return a subset of the columns. If list-like, all elements must either\n",
       "    be positional (i.e. integer indices into the document columns) or strings\n",
       "    that correspond to column names provided either by the user in `names` or\n",
       "    inferred from the document header row(s). For example, a valid list-like\n",
       "    `usecols` parameter would be ``[0, 1, 2]`` or ``['foo', 'bar', 'baz']``.\n",
       "    Element order is ignored, so ``usecols=[0, 1]`` is the same as ``[1, 0]``.\n",
       "    To instantiate a DataFrame from ``data`` with element order preserved use\n",
       "    ``pd.read_csv(data, usecols=['foo', 'bar'])[['foo', 'bar']]`` for columns\n",
       "    in ``['foo', 'bar']`` order or\n",
       "    ``pd.read_csv(data, usecols=['foo', 'bar'])[['bar', 'foo']]``\n",
       "    for ``['bar', 'foo']`` order.\n",
       "\n",
       "    If callable, the callable function will be evaluated against the column\n",
       "    names, returning names where the callable function evaluates to True. An\n",
       "    example of a valid callable argument would be ``lambda x: x.upper() in\n",
       "    ['AAA', 'BBB', 'DDD']``. Using this parameter results in much faster\n",
       "    parsing time and lower memory usage.\n",
       "squeeze : bool, default False\n",
       "    If the parsed data only contains one column then return a Series.\n",
       "prefix : str, optional\n",
       "    Prefix to add to column numbers when no header, e.g. 'X' for X0, X1, ...\n",
       "mangle_dupe_cols : bool, default True\n",
       "    Duplicate columns will be specified as 'X', 'X.1', ...'X.N', rather than\n",
       "    'X'...'X'. Passing in False will cause data to be overwritten if there\n",
       "    are duplicate names in the columns.\n",
       "dtype : Type name or dict of column -> type, optional\n",
       "    Data type for data or columns. E.g. {'a': np.float64, 'b': np.int32,\n",
       "    'c': 'Int64'}\n",
       "    Use `str` or `object` together with suitable `na_values` settings\n",
       "    to preserve and not interpret dtype.\n",
       "    If converters are specified, they will be applied INSTEAD\n",
       "    of dtype conversion.\n",
       "engine : {'c', 'python'}, optional\n",
       "    Parser engine to use. The C engine is faster while the python engine is\n",
       "    currently more feature-complete.\n",
       "converters : dict, optional\n",
       "    Dict of functions for converting values in certain columns. Keys can either\n",
       "    be integers or column labels.\n",
       "true_values : list, optional\n",
       "    Values to consider as True.\n",
       "false_values : list, optional\n",
       "    Values to consider as False.\n",
       "skipinitialspace : bool, default False\n",
       "    Skip spaces after delimiter.\n",
       "skiprows : list-like, int or callable, optional\n",
       "    Line numbers to skip (0-indexed) or number of lines to skip (int)\n",
       "    at the start of the file.\n",
       "\n",
       "    If callable, the callable function will be evaluated against the row\n",
       "    indices, returning True if the row should be skipped and False otherwise.\n",
       "    An example of a valid callable argument would be ``lambda x: x in [0, 2]``.\n",
       "skipfooter : int, default 0\n",
       "    Number of lines at bottom of file to skip (Unsupported with engine='c').\n",
       "nrows : int, optional\n",
       "    Number of rows of file to read. Useful for reading pieces of large files.\n",
       "na_values : scalar, str, list-like, or dict, optional\n",
       "    Additional strings to recognize as NA/NaN. If dict passed, specific\n",
       "    per-column NA values.  By default the following values are interpreted as\n",
       "    NaN: '', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan',\n",
       "    '1.#IND', '1.#QNAN', '<NA>', 'N/A', 'NA', 'NULL', 'NaN', 'n/a',\n",
       "    'nan', 'null'.\n",
       "keep_default_na : bool, default True\n",
       "    Whether or not to include the default NaN values when parsing the data.\n",
       "    Depending on whether `na_values` is passed in, the behavior is as follows:\n",
       "\n",
       "    * If `keep_default_na` is True, and `na_values` are specified, `na_values`\n",
       "      is appended to the default NaN values used for parsing.\n",
       "    * If `keep_default_na` is True, and `na_values` are not specified, only\n",
       "      the default NaN values are used for parsing.\n",
       "    * If `keep_default_na` is False, and `na_values` are specified, only\n",
       "      the NaN values specified `na_values` are used for parsing.\n",
       "    * If `keep_default_na` is False, and `na_values` are not specified, no\n",
       "      strings will be parsed as NaN.\n",
       "\n",
       "    Note that if `na_filter` is passed in as False, the `keep_default_na` and\n",
       "    `na_values` parameters will be ignored.\n",
       "na_filter : bool, default True\n",
       "    Detect missing value markers (empty strings and the value of na_values). In\n",
       "    data without any NAs, passing na_filter=False can improve the performance\n",
       "    of reading a large file.\n",
       "verbose : bool, default False\n",
       "    Indicate number of NA values placed in non-numeric columns.\n",
       "skip_blank_lines : bool, default True\n",
       "    If True, skip over blank lines rather than interpreting as NaN values.\n",
       "parse_dates : bool or list of int or names or list of lists or dict, default False\n",
       "    The behavior is as follows:\n",
       "\n",
       "    * boolean. If True -> try parsing the index.\n",
       "    * list of int or names. e.g. If [1, 2, 3] -> try parsing columns 1, 2, 3\n",
       "      each as a separate date column.\n",
       "    * list of lists. e.g.  If [[1, 3]] -> combine columns 1 and 3 and parse as\n",
       "      a single date column.\n",
       "    * dict, e.g. {'foo' : [1, 3]} -> parse columns 1, 3 as date and call\n",
       "      result 'foo'\n",
       "\n",
       "    If a column or index cannot be represented as an array of datetimes,\n",
       "    say because of an unparseable value or a mixture of timezones, the column\n",
       "    or index will be returned unaltered as an object data type. For\n",
       "    non-standard datetime parsing, use ``pd.to_datetime`` after\n",
       "    ``pd.read_csv``. To parse an index or column with a mixture of timezones,\n",
       "    specify ``date_parser`` to be a partially-applied\n",
       "    :func:`pandas.to_datetime` with ``utc=True``. See\n",
       "    :ref:`io.csv.mixed_timezones` for more.\n",
       "\n",
       "    Note: A fast-path exists for iso8601-formatted dates.\n",
       "infer_datetime_format : bool, default False\n",
       "    If True and `parse_dates` is enabled, pandas will attempt to infer the\n",
       "    format of the datetime strings in the columns, and if it can be inferred,\n",
       "    switch to a faster method of parsing them. In some cases this can increase\n",
       "    the parsing speed by 5-10x.\n",
       "keep_date_col : bool, default False\n",
       "    If True and `parse_dates` specifies combining multiple columns then\n",
       "    keep the original columns.\n",
       "date_parser : function, optional\n",
       "    Function to use for converting a sequence of string columns to an array of\n",
       "    datetime instances. The default uses ``dateutil.parser.parser`` to do the\n",
       "    conversion. Pandas will try to call `date_parser` in three different ways,\n",
       "    advancing to the next if an exception occurs: 1) Pass one or more arrays\n",
       "    (as defined by `parse_dates`) as arguments; 2) concatenate (row-wise) the\n",
       "    string values from the columns defined by `parse_dates` into a single array\n",
       "    and pass that; and 3) call `date_parser` once for each row using one or\n",
       "    more strings (corresponding to the columns defined by `parse_dates`) as\n",
       "    arguments.\n",
       "dayfirst : bool, default False\n",
       "    DD/MM format dates, international and European format.\n",
       "cache_dates : bool, default True\n",
       "    If True, use a cache of unique, converted dates to apply the datetime\n",
       "    conversion. May produce significant speed-up when parsing duplicate\n",
       "    date strings, especially ones with timezone offsets.\n",
       "\n",
       "    .. versionadded:: 0.25.0\n",
       "iterator : bool, default False\n",
       "    Return TextFileReader object for iteration or getting chunks with\n",
       "    ``get_chunk()``.\n",
       "chunksize : int, optional\n",
       "    Return TextFileReader object for iteration.\n",
       "    See the `IO Tools docs\n",
       "    <https://pandas.pydata.org/pandas-docs/stable/io.html#io-chunking>`_\n",
       "    for more information on ``iterator`` and ``chunksize``.\n",
       "compression : {'infer', 'gzip', 'bz2', 'zip', 'xz', None}, default 'infer'\n",
       "    For on-the-fly decompression of on-disk data. If 'infer' and\n",
       "    `filepath_or_buffer` is path-like, then detect compression from the\n",
       "    following extensions: '.gz', '.bz2', '.zip', or '.xz' (otherwise no\n",
       "    decompression). If using 'zip', the ZIP file must contain only one data\n",
       "    file to be read in. Set to None for no decompression.\n",
       "thousands : str, optional\n",
       "    Thousands separator.\n",
       "decimal : str, default '.'\n",
       "    Character to recognize as decimal point (e.g. use ',' for European data).\n",
       "lineterminator : str (length 1), optional\n",
       "    Character to break file into lines. Only valid with C parser.\n",
       "quotechar : str (length 1), optional\n",
       "    The character used to denote the start and end of a quoted item. Quoted\n",
       "    items can include the delimiter and it will be ignored.\n",
       "quoting : int or csv.QUOTE_* instance, default 0\n",
       "    Control field quoting behavior per ``csv.QUOTE_*`` constants. Use one of\n",
       "    QUOTE_MINIMAL (0), QUOTE_ALL (1), QUOTE_NONNUMERIC (2) or QUOTE_NONE (3).\n",
       "doublequote : bool, default ``True``\n",
       "   When quotechar is specified and quoting is not ``QUOTE_NONE``, indicate\n",
       "   whether or not to interpret two consecutive quotechar elements INSIDE a\n",
       "   field as a single ``quotechar`` element.\n",
       "escapechar : str (length 1), optional\n",
       "    One-character string used to escape other characters.\n",
       "comment : str, optional\n",
       "    Indicates remainder of line should not be parsed. If found at the beginning\n",
       "    of a line, the line will be ignored altogether. This parameter must be a\n",
       "    single character. Like empty lines (as long as ``skip_blank_lines=True``),\n",
       "    fully commented lines are ignored by the parameter `header` but not by\n",
       "    `skiprows`. For example, if ``comment='#'``, parsing\n",
       "    ``#empty\\na,b,c\\n1,2,3`` with ``header=0`` will result in 'a,b,c' being\n",
       "    treated as the header.\n",
       "encoding : str, optional\n",
       "    Encoding to use for UTF when reading/writing (ex. 'utf-8'). `List of Python\n",
       "    standard encodings\n",
       "    <https://docs.python.org/3/library/codecs.html#standard-encodings>`_ .\n",
       "dialect : str or csv.Dialect, optional\n",
       "    If provided, this parameter will override values (default or not) for the\n",
       "    following parameters: `delimiter`, `doublequote`, `escapechar`,\n",
       "    `skipinitialspace`, `quotechar`, and `quoting`. If it is necessary to\n",
       "    override values, a ParserWarning will be issued. See csv.Dialect\n",
       "    documentation for more details.\n",
       "error_bad_lines : bool, default True\n",
       "    Lines with too many fields (e.g. a csv line with too many commas) will by\n",
       "    default cause an exception to be raised, and no DataFrame will be returned.\n",
       "    If False, then these \"bad lines\" will dropped from the DataFrame that is\n",
       "    returned.\n",
       "warn_bad_lines : bool, default True\n",
       "    If error_bad_lines is False, and warn_bad_lines is True, a warning for each\n",
       "    \"bad line\" will be output.\n",
       "delim_whitespace : bool, default False\n",
       "    Specifies whether or not whitespace (e.g. ``' '`` or ``'    '``) will be\n",
       "    used as the sep. Equivalent to setting ``sep='\\s+'``. If this option\n",
       "    is set to True, nothing should be passed in for the ``delimiter``\n",
       "    parameter.\n",
       "low_memory : bool, default True\n",
       "    Internally process the file in chunks, resulting in lower memory use\n",
       "    while parsing, but possibly mixed type inference.  To ensure no mixed\n",
       "    types either set False, or specify the type with the `dtype` parameter.\n",
       "    Note that the entire file is read into a single DataFrame regardless,\n",
       "    use the `chunksize` or `iterator` parameter to return the data in chunks.\n",
       "    (Only valid with C parser).\n",
       "memory_map : bool, default False\n",
       "    If a filepath is provided for `filepath_or_buffer`, map the file object\n",
       "    directly onto memory and access the data directly from there. Using this\n",
       "    option can improve performance because there is no longer any I/O overhead.\n",
       "float_precision : str, optional\n",
       "    Specifies which converter the C engine should use for floating-point\n",
       "    values. The options are `None` for the ordinary converter,\n",
       "    `high` for the high-precision converter, and `round_trip` for the\n",
       "    round-trip converter.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "DataFrame or TextParser\n",
       "    A comma-separated values (csv) file is returned as two-dimensional\n",
       "    data structure with labeled axes.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "DataFrame.to_csv : Write DataFrame to a comma-separated values (csv) file.\n",
       "read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
       "read_fwf : Read a table of fixed-width formatted lines into DataFrame.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> pd.read_csv('data.csv')  # doctest: +SKIP\n",
       "\u001b[0;31mFile:\u001b[0m      /usr/local/lib/python3.8/dist-packages/pandas/io/parsers.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "execution_count": 7,
     "metadata": {
     },
     "output_type": "execute_result",
     "start": 0
    }
   ],
   "source": [
    "?pd.read_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "To load the dataframe we are using in this notebook, we will provide the path to the file: ../data/Iris/Iris_data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    ">Load the dataframe, read it into a Panda's DataFrame and assign it to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
    }
   },
   "outputs": [
   ],
   "source": [
    "df = pd.read_csv(\"../data/Iris/Iris_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
    }
   },
   "outputs": [
   ],
   "source": [
    "# %load ../solutions/02_02.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**To have a look at the first 5 rows of df, we can use the *head* method.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0  1.0            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1  2.0            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2  3.0            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3  4.0            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4  5.0            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 10,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    ">Have a look at the last 3 rows of df using the tail method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>151.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>152.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>153.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  \\\n",
       "151  151.0            6.5           3.0            5.2           2.0   \n",
       "152  152.0            6.2           3.4            5.4           2.3   \n",
       "153  153.0            5.9           3.0            5.1           1.8   \n",
       "\n",
       "            Species  \n",
       "151  Iris-virginica  \n",
       "152  Iris-virginica  \n",
       "153  Iris-virginica  "
      ]
     },
     "execution_count": 11,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
    }
   },
   "outputs": [
   ],
   "source": [
    "# %load ../solutions/02_03.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "___\n",
    "## General information about the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**To get the size of the datasets, we can use the *shape* attribute.**  \n",
    "The first number is the number of row, the second one the number of columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    ">Show the shape of df (do not put brackets at the end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "jupyter": {
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154, 6)"
      ]
     },
     "execution_count": 21,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "jupyter": {
    }
   },
   "outputs": [
   ],
   "source": [
    "# %load ../solutions/02_04.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    ">Get the names of the columns and info about them (number of non null and type) using the info method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "jupyter": {
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 154 entries, 0 to 153\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Id             153 non-null    float64\n",
      " 1   SepalLengthCm  153 non-null    float64\n",
      " 2   SepalWidthCm   152 non-null    float64\n",
      " 3   PetalLengthCm  152 non-null    float64\n",
      " 4   PetalWidthCm   152 non-null    float64\n",
      " 5   Species        153 non-null    object \n",
      "dtypes: float64(5), object(1)\n",
      "memory usage: 7.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "jupyter": {
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 154 entries, 0 to 153\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Id             153 non-null    float64\n",
      " 1   SepalLengthCm  153 non-null    float64\n",
      " 2   SepalWidthCm   152 non-null    float64\n",
      " 3   PetalLengthCm  152 non-null    float64\n",
      " 4   PetalWidthCm   152 non-null    float64\n",
      " 5   Species        153 non-null    object \n",
      "dtypes: float64(5), object(1)\n",
      "memory usage: 7.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# %load ../solutions/02_05.py\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    ">get the columns of the dataframe using the columns attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "jupyter": {
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm',\n",
       "       'Species'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
    }
   },
   "outputs": [
   ],
   "source": [
    "# %load ../solutions/02_06.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Display settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We can check the dipslay option of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "jupyter": {
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 29,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    ">Force pandas to display 25 rows by changing the value of the above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "jupyter": {
    }
   },
   "outputs": [
   ],
   "source": [
    "pd.options.display.max_rows = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "jupyter": {
    }
   },
   "outputs": [
   ],
   "source": [
    "# %load ../solutions/02_07.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "___\n",
    "## _Subsetting_\n",
    "We can subset a dataframe by label, by index or a combination of both.  \n",
    "There are different ways to do it, using .loc, .iloc and also [].  \n",
    "See [documentation ](https://pandas.pydata.org/pandas-docs/stable/indexing.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    ">Display the 'SepalLengthCm' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "jupyter": {
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      5.1\n",
       "1      4.9\n",
       "2      4.7\n",
       "3      4.6\n",
       "4      5.0\n",
       "      ... \n",
       "149    6.7\n",
       "150    6.3\n",
       "151    6.5\n",
       "152    6.2\n",
       "153    5.9\n",
       "Name: SepalLengthCm, Length: 154, dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['SepalLengthCm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "jupyter": {
    }
   },
   "outputs": [
   ],
   "source": [
    "# %load ../solutions/02_08.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "*Note:* We could also use df.SepalLengthCm   ->   not a great idea because it could be mixed with methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    ">Have a look at the 12th observation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "jupyter": {
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                        12\n",
       "SepalLengthCm            4.8\n",
       "SepalWidthCm             3.4\n",
       "PetalLengthCm            1.6\n",
       "PetalWidthCm             0.2\n",
       "Species          Iris-setosa\n",
       "Name: 11, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using .iloc (uses positions, \"i\" stands for integer)\n",
    "df.iloc[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "jupyter": {
    }
   },
   "outputs": [
   ],
   "source": [
    "# %load ../solutions/02_09.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "jupyter": {
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                        12\n",
       "SepalLengthCm            4.8\n",
       "SepalWidthCm             3.4\n",
       "PetalLengthCm            1.6\n",
       "PetalWidthCm             0.2\n",
       "Species          Iris-setosa\n",
       "Name: 11, dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using .loc (uses indexes and labels)\n",
    "df.loc[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "jupyter": {
    }
   },
   "outputs": [
   ],
   "source": [
    "# %load ../solutions/02_10.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    ">Display the ***SepalLengthCm*** of the last three observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "jupyter": {
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151    6.5\n",
       "152    6.2\n",
       "153    5.9\n",
       "Name: SepalLengthCm, dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using .iloc\n",
    "df.iloc[-3:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "jupyter": {
    }
   },
   "outputs": [
   ],
   "source": [
    "# %load ../solutions/02_11.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "jupyter": {
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151    6.5\n",
       "152    6.2\n",
       "153    5.9\n",
       "Name: SepalLengthCm, dtype: float64"
      ]
     },
     "execution_count": 61,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using .loc\n",
    "df.loc[151:, 'SepalLengthCm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "jupyter": {
    },
    "scrolled": true
   },
   "outputs": [
   ],
   "source": [
    "# %load ../solutions/02_12.py\n",
    "df.loc[151:, 'SepalLengthCm']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**And finally look at the PetalLengthCm and PetalWidthCm of the 146th, the 8th and the 1rst observations:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "jupyter": {
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>5.1</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PetalLengthCm  PetalWidthCm\n",
       "145            5.1           2.3\n",
       "7              1.5           0.2\n",
       "0              1.4           0.2"
      ]
     },
     "execution_count": 65,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using .iloc\n",
    "df.iloc[[145, 7, 0], [3, -2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "jupyter": {
    }
   },
   "outputs": [
   ],
   "source": [
    "# %load ../solutions/02_13.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
   ],
   "source": [
    "# using .loc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
   ],
   "source": [
    "# %load ../solutions/02_14.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**!!WARNING!!**  Unlike Python and ``.iloc``, the end value in a range specified by ``.loc`` **includes** the last index specified. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
   ],
   "source": [
    "df.iloc[5:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
   ],
   "source": [
    "df.loc[5:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "___\n",
    "## Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**We can also use condition(s) to filter.**  \n",
    "We want to display the rows of df where **PetalWidthCm** is greater than 2. We will start by creating a mask with this condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
   ],
   "source": [
    "mask_PW = df['PetalWidthCm'] > 2\n",
    "mask_PW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Note that this return boleans. If we pass this mask to our dataframe, it will display only the rows where the mask is True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
   ],
   "source": [
    "df[mask_PW]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    ">Display the rows of df where ***PetalWidthCm*** is greater than 2 and ***PetalLengthCm*** is less than 5.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
   ],
   "source": [
    "# %load ../solutions/02_15.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "___\n",
    "## Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**We can get the number of unique values from a certain column by using the *nunique* method.**  \n",
    "For example, we can get the number of unique values from the Species column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
   ],
   "source": [
    "df['Species'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**We can also get the list of unique values from a certain column by using the *unique* method.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    ">Return the list of unique values from the Species column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
   ],
   "source": [
    "# %load ../solutions/02_16.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**To get the count of the different values of a column, we can use the *value_counts* method.**  \n",
    "For example, for the Species column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
   ],
   "source": [
    "df['Species'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**If we want to know the count of NaN values, we have to pass the value *Flase* to the parameter *dropna* (set to *True* by default).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    ">Return the proportion for each species, including the NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
   ],
   "source": [
    "# %load ../solutions/02_17.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**To get the proportion instead of the count of these values, we have to pass the value *True* to the parameter *normalize*.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    ">Return the proportion for each species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
   ],
   "source": [
    "# %load ../solutions/02_18.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**We can use the *isnull* method to know if a value is null or not. It returns booleans.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
   ],
   "source": [
    "df['PetalLengthCm'].isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**We can apply different methods one after the other.**.  \n",
    "For example, we could apply to method *sum* after the method *isnull* to know the number of null observations in the PetalLengthCm column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    ">Get the number of null values for ***PetalLengthCm***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
   ],
   "source": [
    "# %load ../solutions/02_19.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    ">Using the index attribute, get the indexes of the observation without PetalLengthCm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
   ],
   "source": [
    "# %load ../solutions/02_20.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Use the [dropna](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html) method to remove the row which only has nan values.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    ">Get the help for the dropna method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
   ],
   "source": [
    "# %load ../solutions/02_21.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    ">Use the dropna method to remove the row of df where all of the values are nan, and assign it to df_2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
   ],
   "source": [
    "# %load ../solutions/02_22.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We can use a f-string to format a string. We have to write a ***f*** before the quotation mark, and write what you want to format between curly brackets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
   ],
   "source": [
    "print(f'shape of df: {df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    ">Print the number of rows of df_2 using a f_string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
   ],
   "source": [
    "# %load ../solutions/02_23.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    ">Use the dropna method to remove the rows of df_2 which contains any nan values, and assign it to df_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
   ],
   "source": [
    "# %load ../solutions/02_24.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    ">Print the number of rows of df_3 using a f_string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
   ],
   "source": [
    "# %load ../solutions/02_25.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    ">Remove the duplicates rows from df_3, and assign the new dataframe to df_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
   ],
   "source": [
    "# %load ../solutions/02_26.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
   ],
   "source": [
    "# checking the shape of df_4\n",
    "df_4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "___\n",
    "## _Some stats_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    ">Use the describe method to see how the data is distributed (numerical features only!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
   ],
   "source": [
    "# %load ../solutions/02_27.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We can convert the **Id** column to string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
   ],
   "source": [
    "df_4['Id'] = df_4['Id'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
   ],
   "source": [
    "df_4.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We can also change the **Species** column to save memory space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
   ],
   "source": [
    "df_4['Species'] = df_4['Species'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    ">Using the dtypes attribute, check the types of the columns of df_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
   ],
   "source": [
    "# %load ../solutions/02_28.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We can also use the functions count(), mean(), sum(), median(), std(), min() and max() separately if we are only interested in one of those."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    ">Get the minimum for each numerical column of df_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
   ],
   "source": [
    "# %load ../solutions/02_29.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    ">Calculate the maximum of the ***PetalLengthCm***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
   ],
   "source": [
    "# %load ../solutions/02_30.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**We can also get information for each type of flower using the groupby methode.**  \n",
    "\n",
    ">Get the median for each ***Species***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
   ],
   "source": [
    "# %load ../solutions/02_31.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Saving the dataframe as a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    ">Save df_4 using this path: '../data/my_data/my_iris.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
   ],
   "source": [
    "# %load ../solutions/02_32.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
   ],
   "source": [
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (system-wide)",
   "language": "python",
   "metadata": {
    "cocalc": {
     "description": "Python 3 programming language",
     "priority": 100,
     "url": "https://www.python.org/"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}